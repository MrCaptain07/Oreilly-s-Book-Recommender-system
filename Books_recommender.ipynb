{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c72b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bb5cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Books data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\somut\\AppData\\Local\\Temp\\ipykernel_14220\\554522316.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Books = pd.read_csv(\"Books.csv\", on_bad_lines=\"skip\")\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Books data...\")\n",
    "Books = pd.read_csv(\"Books.csv\", on_bad_lines=\"skip\")\n",
    "Books = Books[[\"ISBN\",\"Book-Title\",\"Book-Author\",\"Year-Of-Publication\",\"Publisher\",\"Image-URL-L\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d5dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 271360 books\n",
      "Sample books data:\n",
      "         ISBN                                              Title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "                 Author  Year                   Publisher  \\\n",
      "0    Mark P. O. Morford  2002     Oxford University Press   \n",
      "1  Richard Bruce Wright  2001       HarperFlamingo Canada   \n",
      "2          Carlo D'Este  1991             HarperPerennial   \n",
      "3      Gina Bari Kolata  1999        Farrar Straus Giroux   \n",
      "4       E. J. W. Barber  1999  W. W. Norton &amp; Company   \n",
      "\n",
      "                                           Image_URL  \n",
      "0  http://images.amazon.com/images/P/0195153448.0...  \n",
      "1  http://images.amazon.com/images/P/0002005018.0...  \n",
      "2  http://images.amazon.com/images/P/0060973129.0...  \n",
      "3  http://images.amazon.com/images/P/0374157065.0...  \n",
      "4  http://images.amazon.com/images/P/0393045218.0...  \n",
      "Loading Users data...\n",
      "Loaded 278858 users\n",
      "Sample users data:\n",
      "   User-ID                            Location   Age\n",
      "0        1                  nyc, new york, usa   NaN\n",
      "1        2           stockton, california, usa  18.0\n",
      "2        3     moscow, yukon territory, russia   NaN\n",
      "3        4           porto, v.n.gaia, portugal  17.0\n",
      "4        5  farnborough, hants, united kingdom   NaN\n",
      "Loading Ratings data...\n",
      "Loaded 1149780 ratings\n",
      "Sample ratings data:\n",
      "   User-ID        ISBN  Book-Rating\n",
      "0   276725  034545104X            0\n",
      "1   276726  0155061224            5\n",
      "2   276727  0446520802            0\n",
      "3   276729  052165615X            3\n",
      "4   276729  0521795028            6\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "Books.rename(columns={\n",
    "    \"Book-Title\": \"Title\",\n",
    "    \"Book-Author\": \"Author\", \n",
    "    \"Year-Of-Publication\": \"Year\",\n",
    "    \"Publisher\": \"Publisher\",\n",
    "    \"Image-URL-L\": \"Image_URL\"\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"Loaded {len(Books)} books\")\n",
    "print(\"Sample books data:\")\n",
    "print(Books.head())\n",
    "\n",
    "# Cell 3: Load Users Data\n",
    "print(\"Loading Users data...\")\n",
    "Users = pd.read_csv(\"Users.csv\", on_bad_lines=\"skip\")\n",
    "print(f\"Loaded {len(Users)} users\")\n",
    "print(\"Sample users data:\")\n",
    "print(Users.head())\n",
    "\n",
    "# Cell 4: Load Ratings Data\n",
    "print(\"Loading Ratings data...\")\n",
    "ratings = pd.read_csv(\"Ratings.csv\", on_bad_lines=\"skip\")\n",
    "print(f\"Loaded {len(ratings)} ratings\")\n",
    "print(\"Sample ratings data:\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e85ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering active users (>200 ratings)...\n",
      "Users with >200 ratings: 899\n",
      "Original ratings: 1149780\n",
      "Filtered ratings: 526356\n",
      "Reduction: 623424 ratings removed\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Filter Active Users (>200 ratings)\n",
    "print(\"Filtering active users (>200 ratings)...\")\n",
    "user_rating_counts = ratings[\"User-ID\"].value_counts()\n",
    "print(f\"Users with >200 ratings: {sum(user_rating_counts > 200)}\")\n",
    "\n",
    "active_users = user_rating_counts[user_rating_counts > 200].index\n",
    "ratings_filtered = ratings[ratings[\"User-ID\"].isin(active_users)]\n",
    "\n",
    "print(f\"Original ratings: {len(ratings)}\")\n",
    "print(f\"Filtered ratings: {len(ratings_filtered)}\")\n",
    "print(f\"Reduction: {len(ratings) - len(ratings_filtered)} ratings removed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f64fd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging books and ratings...\n",
      "Merged dataset has 487671 entries\n",
      "Sample merged data:\n",
      "   User-ID        ISBN  Book-Rating  \\\n",
      "0   277427  002542730X           10   \n",
      "1   277427  0026217457            0   \n",
      "2   277427  003008685X            8   \n",
      "3   277427  0030615321            0   \n",
      "4   277427  0060002050            0   \n",
      "\n",
      "                                               Title                 Author  \\\n",
      "0  Politically Correct Bedtime Stories: Modern Ta...      James Finn Garner   \n",
      "1                 Vegetarian Times Complete Cookbook             Lucy  Moll   \n",
      "2                                           Pioneers  James Fenimore Cooper   \n",
      "3   Ask for May, Settle for June (A Doonesbury book)          G. B. Trudeau   \n",
      "4                  On a Wicked Dawn (Cynster Novels)      Stephanie Laurens   \n",
      "\n",
      "   Year                  Publisher  \\\n",
      "0  1994  John Wiley &amp; Sons Inc   \n",
      "1  1995      John Wiley &amp; Sons   \n",
      "2  1974           Thomson Learning   \n",
      "3  1982        Henry Holt &amp; Co   \n",
      "4  2002                 Avon Books   \n",
      "\n",
      "                                           Image_URL  \n",
      "0  http://images.amazon.com/images/P/002542730X.0...  \n",
      "1  http://images.amazon.com/images/P/0026217457.0...  \n",
      "2  http://images.amazon.com/images/P/003008685X.0...  \n",
      "3  http://images.amazon.com/images/P/0030615321.0...  \n",
      "4  http://images.amazon.com/images/P/0060002050.0...  \n",
      "Counting ratings per book...\n",
      "Books with most ratings:\n",
      "                                                  Title  num_of_rating\n",
      "156313                                      Wild Animus            363\n",
      "19140                             Bridget Jones's Diary            277\n",
      "130224                        The Lovely Bones: A Novel            270\n",
      "132891                                     The Notebook            241\n",
      "133898                                The Pelican Brief            236\n",
      "132222                       The Nanny Diaries: A Novel            230\n",
      "3711                                    A Painted House            228\n",
      "34995   Divine Secrets of the Ya-Ya Sisterhood: A Novel            228\n",
      "124207                                         The Firm            227\n",
      "121280                                The Da Vinci Code            224\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Merge Books and Ratings\n",
    "print(\"Merging books and ratings...\")\n",
    "ratings_with_books = ratings_filtered.merge(Books, on=\"ISBN\")\n",
    "print(f\"Merged dataset has {len(ratings_with_books)} entries\")\n",
    "print(\"Sample merged data:\")\n",
    "print(ratings_with_books.head())\n",
    "\n",
    "# Cell 7: Count Ratings Per Book\n",
    "print(\"Counting ratings per book...\")\n",
    "number_ratings = ratings_with_books.groupby(\"Title\")[\"Book-Rating\"].count().reset_index()\n",
    "number_ratings.rename(columns={\"Book-Rating\":\"num_of_rating\"}, inplace=True)\n",
    "\n",
    "print(\"Books with most ratings:\")\n",
    "print(number_ratings.sort_values('num_of_rating', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dadd6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging with rating counts...\n",
      "Filtering books with at least 50 ratings...\n",
      "Books with >=50 ratings: 742\n",
      "Final dataset entries: 61853\n",
      "Removing duplicates...\n",
      "Before removing duplicates: 61853\n",
      "After removing duplicates: 59850\n",
      "Unique books: 742\n",
      "Unique users: 888\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Filter Books with At Least 50 Ratings\n",
    "print(\"Merging with rating counts...\")\n",
    "final_ratings = ratings_with_books.merge(number_ratings, on=\"Title\")\n",
    "\n",
    "print(\"Filtering books with at least 50 ratings...\")\n",
    "final_ratings = final_ratings[final_ratings[\"num_of_rating\"] >= 50]\n",
    "\n",
    "print(f\"Books with >=50 ratings: {final_ratings['Title'].nunique()}\")\n",
    "print(f\"Final dataset entries: {len(final_ratings)}\")\n",
    "\n",
    "# Cell 9: Remove Duplicates\n",
    "print(\"Removing duplicates...\")\n",
    "print(f\"Before removing duplicates: {len(final_ratings)}\")\n",
    "\n",
    "final_ratings.drop_duplicates(subset=[\"Title\", \"User-ID\"], inplace=True)\n",
    "\n",
    "print(f\"After removing duplicates: {len(final_ratings)}\")\n",
    "print(f\"Unique books: {final_ratings['Title'].nunique()}\")\n",
    "print(f\"Unique users: {final_ratings['User-ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c31b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pivot table...\n",
      "Pivot table shape: (742, 888)\n",
      "Books (rows): 742\n",
      "Users (columns): 888\n",
      "Sparsity: 90.92%\n",
      "Preparing data for model training...\n",
      "Converting to sparse matrix...\n",
      "Sparse matrix shape: (742, 888)\n",
      "Non-zero elements: 14961\n",
      "Density: 2.2706%\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Create Pivot Table\n",
    "print(\"Creating pivot table...\")\n",
    "book_pivot = final_ratings.pivot_table(\n",
    "    columns=\"User-ID\", \n",
    "    index=\"Title\", \n",
    "    values=\"Book-Rating\"\n",
    ")\n",
    "\n",
    "print(f\"Pivot table shape: {book_pivot.shape}\")\n",
    "print(f\"Books (rows): {book_pivot.shape[0]}\")\n",
    "print(f\"Users (columns): {book_pivot.shape[1]}\")\n",
    "print(f\"Sparsity: {(book_pivot.isna().sum().sum() / (book_pivot.shape[0] * book_pivot.shape[1])) * 100:.2f}%\")\n",
    "\n",
    "# Cell 11: Prepare Data for Model Training\n",
    "print(\"Preparing data for model training...\")\n",
    "\n",
    "# Fill NaN values with 0\n",
    "book_pivot_filled = book_pivot.fillna(0)\n",
    "\n",
    "# Convert to sparse matrix for memory efficiency\n",
    "print(\"Converting to sparse matrix...\")\n",
    "book_sparse = csr_matrix(book_pivot_filled.values)\n",
    "\n",
    "print(f\"Sparse matrix shape: {book_sparse.shape}\")\n",
    "print(f\"Non-zero elements: {book_sparse.nnz}\")\n",
    "print(f\"Density: {book_sparse.nnz / (book_sparse.shape[0] * book_sparse.shape[1]) * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0532aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN model...\n",
      "KNN model trained successfully!\n",
      "Model metric: cosine\n",
      "Model algorithm: brute\n",
      "Saving model and data...\n",
      "All files saved successfully!\n",
      "Saved files:\n",
      "- model.pkl (trained KNN model)\n",
      "- books_name.pkl (book titles)\n",
      "- final_ratings.pkl (processed ratings data)\n",
      "- book_pivot.pkl (pivot table)\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Train KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "model = NearestNeighbors(algorithm=\"brute\", metric=\"cosine\")\n",
    "model.fit(book_sparse)\n",
    "\n",
    "print(\"KNN model trained successfully!\")\n",
    "print(f\"Model metric: {model.metric}\")\n",
    "print(f\"Model algorithm: {model.algorithm}\")\n",
    "\n",
    "# Cell 13: Save Model and Data\n",
    "print(\"Saving model and data...\")\n",
    "\n",
    "# Save all components\n",
    "pkl.dump(model, open(\"model.pkl\", \"wb\"))\n",
    "pkl.dump(book_pivot.index, open(\"books_name.pkl\", \"wb\"))\n",
    "pkl.dump(final_ratings, open(\"final_ratings.pkl\", \"wb\"))\n",
    "pkl.dump(book_pivot, open(\"book_pivot.pkl\", \"wb\"))\n",
    "\n",
    "print(\"All files saved successfully!\")\n",
    "print(\"Saved files:\")\n",
    "print(\"- model.pkl (trained KNN model)\")\n",
    "print(\"- books_name.pkl (book titles)\")\n",
    "print(\"- final_ratings.pkl (processed ratings data)\")\n",
    "print(\"- book_pivot.pkl (pivot table)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6a1990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Define Recommendation Function\n",
    "def recommend_book(book_name, model, book_pivot, n_recommendations=5):\n",
    "    \"\"\"\n",
    "    Get book recommendations based on collaborative filtering\n",
    "    \n",
    "    Parameters:\n",
    "    book_name (str): Name of the book to get recommendations for\n",
    "    model: Trained KNN model\n",
    "    book_pivot: Pivot table with books and ratings\n",
    "    n_recommendations (int): Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "    list: List of recommended book titles\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find the book's row index in the pivot table\n",
    "        book_id = np.where(book_pivot.index == book_name)[0][0]\n",
    "    except IndexError:\n",
    "        return [f\"Book '{book_name}' not found in database.\"]\n",
    "    \n",
    "    # Create query vector (filled with 0 for missing values)\n",
    "    query = book_pivot.iloc[book_id, :].fillna(0).values.reshape(1, -1)\n",
    "\n",
    "    # Get nearest neighbors (n_recommendations + 1 to exclude the input book)\n",
    "    distances, indices = model.kneighbors(query, n_neighbors=n_recommendations + 1)\n",
    "\n",
    "    # Collect recommended books (excluding the input book itself)\n",
    "    recommendations = []\n",
    "    for i in range(1, len(indices[0])):  # Start from 1 to skip the input book\n",
    "        book_title = book_pivot.index[indices[0][i]]\n",
    "        distance = distances[0][i]\n",
    "        recommendations.append((book_title, distance))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "print(\"Recommendation function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1330508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING BOOK RECOMMENDATION SYSTEM\n",
      "============================================================\n",
      "\n",
      "Sample books available in the database:\n",
      "1. 1984\n",
      "2. 1st to Die: A Novel\n",
      "3. 2nd Chance\n",
      "4. 4 Blondes\n",
      "5. 84 Charing Cross Road\n",
      "6. A Bend in the Road\n",
      "7. A Case of Need\n",
      "8. A Child Called \\It\\\": One Child's Courage to Survive\"\n",
      "9. A Civil Action\n",
      "10. A Cry In The Night\n",
      "\n",
      "üîç Getting recommendations for: '1984'\n",
      "------------------------------------------------------------\n",
      "üìö Recommended books:\n",
      "1. Animal Farm\n",
      "   Similarity Score: 0.2695\n",
      "\n",
      "2. The Catcher in the Rye\n",
      "   Similarity Score: 0.2231\n",
      "\n",
      "3. Lord of the Flies\n",
      "   Similarity Score: 0.2215\n",
      "\n",
      "4. The Handmaid's Tale\n",
      "   Similarity Score: 0.2128\n",
      "\n",
      "5. Slaughterhouse Five or the Children's Crusade: A Duty Dance With Death\n",
      "   Similarity Score: 0.2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Test the Recommendation System\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING BOOK RECOMMENDATION SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display available books for testing\n",
    "print(\"\\nSample books available in the database:\")\n",
    "sample_books = book_pivot.index[:10].tolist()\n",
    "for i, book in enumerate(sample_books, 1):\n",
    "    print(f\"{i}. {book}\")\n",
    "\n",
    "# Test with the first book\n",
    "if len(sample_books) > 0:\n",
    "    test_book = sample_books[0]\n",
    "    print(f\"\\nüîç Getting recommendations for: '{test_book}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    recommendations = recommend_book(test_book, model, book_pivot, n_recommendations=5)\n",
    "    \n",
    "    if isinstance(recommendations[0], str) and \"not found\" in recommendations[0]:\n",
    "        print(recommendations[0])\n",
    "    else:\n",
    "        print(\"üìö Recommended books:\")\n",
    "        for i, (book_title, similarity_score) in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {book_title}\")\n",
    "            print(f\"   Similarity Score: {1-similarity_score:.4f}\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b1ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "INTERACTIVE BOOK RECOMMENDATION TESTING\n",
      "==================================================\n",
      "\n",
      "Database contains 742 books\n",
      "\n",
      "Some popular books you can try:\n",
      "1. Wild Animus (363 ratings)\n",
      "2. Bridget Jones's Diary (277 ratings)\n",
      "3. The Lovely Bones: A Novel (270 ratings)\n",
      "4. The Notebook (241 ratings)\n",
      "5. The Pelican Brief (236 ratings)\n",
      "\n",
      "To test recommendations, use:\n",
      "recommendations = recommend_book('BOOK_NAME_HERE', model, book_pivot)\n",
      "\n",
      "Example:\n",
      "recommendations = recommend_book('The Lovely Bones: A Novel', model, book_pivot)\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING SUMMARY\n",
      "============================================================\n",
      "‚úÖ Total books in model: 742\n",
      "‚úÖ Total users: 888\n",
      "‚úÖ Total ratings processed: 59,850\n",
      "‚úÖ Matrix density: 2.2706%\n",
      "‚úÖ Average ratings per book: 80.7\n",
      "‚úÖ Average ratings per user: 67.4\n",
      "\n",
      "üìÅ Model files saved:\n",
      "   - model.pkl (0.17 MB)\n",
      "   - book_pivot.pkl\n",
      "   - final_ratings.pkl\n",
      "   - books_name.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Interactive Testing Function\n",
    "def test_recommendations_interactive():\n",
    "    \"\"\"\n",
    "    Interactive function to test recommendations with any book\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"INTERACTIVE BOOK RECOMMENDATION TESTING\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nDatabase contains {len(book_pivot.index)} books\")\n",
    "    \n",
    "    # Show some popular books\n",
    "    print(\"\\nSome popular books you can try:\")\n",
    "    popular_books = final_ratings.groupby('Title')['num_of_rating'].first().sort_values(ascending=False).head(5)\n",
    "    for i, (book, rating_count) in enumerate(popular_books.items(), 1):\n",
    "        print(f\"{i}. {book} ({rating_count} ratings)\")\n",
    "    \n",
    "    print(\"\\nTo test recommendations, use:\")\n",
    "    print(\"recommendations = recommend_book('BOOK_NAME_HERE', model, book_pivot)\")\n",
    "    print(\"\\nExample:\")\n",
    "    print(\"recommendations = recommend_book('The Lovely Bones: A Novel', model, book_pivot)\")\n",
    "\n",
    "# Run the interactive testing function\n",
    "test_recommendations_interactive()\n",
    "\n",
    "# Cell 17: Model Statistics and Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"‚úÖ Total books in model: {len(book_pivot.index):,}\")\n",
    "print(f\"‚úÖ Total users: {book_pivot.shape[1]:,}\")\n",
    "print(f\"‚úÖ Total ratings processed: {len(final_ratings):,}\")\n",
    "print(f\"‚úÖ Matrix density: {(book_sparse.nnz / (book_sparse.shape[0] * book_sparse.shape[1]) * 100):.4f}%\")\n",
    "print(f\"‚úÖ Average ratings per book: {final_ratings.groupby('Title').size().mean():.1f}\")\n",
    "print(f\"‚úÖ Average ratings per user: {final_ratings.groupby('User-ID').size().mean():.1f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Model files saved:\")\n",
    "print(f\"   - model.pkl ({round(pkl.dumps(model).__sizeof__()/1024/1024, 2)} MB)\")\n",
    "print(f\"   - book_pivot.pkl\")\n",
    "print(f\"   - final_ratings.pkl\") \n",
    "print(f\"   - books_name.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
